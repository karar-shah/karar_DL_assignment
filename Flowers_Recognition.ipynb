{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\producer\\.conda\\envs\\tensorflow\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n",
      "dandelion\n",
      "flowers\n",
      "rose\n",
      "sunflower\n",
      "tulip\n"
     ]
    }
   ],
   "source": [
    "# Loading Data And Defining Features And Labels\n",
    "directory = Path(r\"C:\\Users\\Producer\\Downloads\\Compressed\\flowers\")\n",
    "\n",
    "image_names = []\n",
    "data_images = []\n",
    "labels = []\n",
    "\n",
    "# Iterating Over Directory To Extract Sub Directories\n",
    "for dir in directory.iterdir():\n",
    "  image_names.append(dir.name)\n",
    "  print(dir.name)\n",
    "# Iterating Over Sub Directories To Extract Lables\n",
    "  for imgpath in dir.iterdir():\n",
    "    if imgpath.name.endswith(\"jpg\"):\n",
    "      labels.append(dir.name)\n",
    "      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)\n",
    "      imgarr = cv2.resize(imgarr, (320,240))\n",
    "      data_images.append(imgarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maping the string label into numeric \n",
    "df=pd.DataFrame(labels)\n",
    "labels=df[0].map({\"rose\":0,\"sunflower\":1,\"tulip\":2,\"daisy\":3,\"dandelion\":4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting in train-test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data and label spliting by machine learning libarary\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data_images,labels,test_size=.40,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data into numpy array and data type float\n",
    "X_train=np.asarray(X_train).astype(\"float32\")\n",
    "X_test=np.asarray(X_test).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data is :(2593, 240, 320)\n",
      "shape of training label is :(2593,)\n",
      "shape of testing data is :(1730, 240, 320)\n",
      "shape of testing label is :(1730,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of training data,testing data,training labels,testing labels\n",
    "print(f\"shape of training data is :{X_train.shape}\\nshape of training label is :{y_train.shape}\\nshape of testing data is :{X_test.shape}\\nshape of testing label is :{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping images array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "X_train=X_train.reshape(2593,320*240)\n",
    "X_test=X_test.reshape(1730,320*240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145., 147., 148., ...,  15.,  15.,  15.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#check value of train data\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42., 36., 45., ..., 70., 70., 66.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value of test data\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and doing one hot-encoding of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing keras libararies\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               19661056  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 19,702,533\n",
      "Trainable params: 19,702,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model building\n",
    "network=Sequential()\n",
    "network.add(Dense(256,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "network.add(Dropout(0.2))\n",
    "network.add(Dense(128,activation=\"relu\"))\n",
    "#network.add(Dropout(0.2))\n",
    "network.add(Dense(64,activation=\"relu\"))\n",
    "network.add(Dropout(0.2))\n",
    "network.add(Dense(5,activation=\"softmax\"))\n",
    "#model summary\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation Step\n",
    "network.compile(optimizer=RMSprop(0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 [==============================] - 33s 256ms/step - loss: 2.3027 - accuracy: 0.2218\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 34s 262ms/step - loss: 1.6024 - accuracy: 0.2364\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 34s 259ms/step - loss: 1.5898 - accuracy: 0.2692\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 32s 248ms/step - loss: 1.5780 - accuracy: 0.2669\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 36s 278ms/step - loss: 1.5696 - accuracy: 0.2761\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 40s 309ms/step - loss: 1.5588 - accuracy: 0.2854\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 36s 280ms/step - loss: 1.5608 - accuracy: 0.2811\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 34s 259ms/step - loss: 1.5460 - accuracy: 0.2912\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 34s 265ms/step - loss: 1.5311 - accuracy: 0.2869\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 33s 253ms/step - loss: 1.5435 - accuracy: 0.2919\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 32s 244ms/step - loss: 1.5277 - accuracy: 0.2985\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 33s 251ms/step - loss: 1.5126 - accuracy: 0.3216\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 35s 267ms/step - loss: 1.5097 - accuracy: 0.3070\n",
      "Epoch 14/100\n",
      " 70/130 [===============>..............] - ETA: 15s - loss: 1.5118 - accuracy: 0.3107"
     ]
    }
   ],
   "source": [
    "history=network.fit(X_train, y_train,batch_size=20,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
